<?php

return [
    "Node.js handles async operations by default, but CPU-heavy tasks can still block the event loop.",
    "Worker Threads in Node.js allow you to run heavy computations in parallel on separate threads.",
    "Streams process data chunk by chunk — useful for large files or real-time pipelines.",
    "Worker Threads are ideal for CPU-bound tasks like encryption, image processing, or math operations.",
    "Streams shine when working with I/O-bound tasks like reading/writing files or network requests.",
    "We use streams in Node to process large JSON and CSV files without loading them fully into memory.",
    "With Worker Threads, each thread runs in its own context with a dedicated message channel.",
    "Node.js streams follow a readable/writable/transform model — very composable.",
    "If your processing logic is CPU-intensive, streams won’t help — use workers instead.",
    "We offload video encoding to Worker Threads to avoid freezing our API server.",
    "Backpressure in streams is essential for controlling memory usage and speed.",
    "The `worker_threads` module is built into Node.js since v10.5.0 (stable in v12).",
    "Use `Readable.from()` to create streams from async sources easily.",
    "Communicating between threads is done via message passing, not shared memory.",
    "In our backend, we use streams to process millions of rows from the database in batches.",
    "Worker Threads can be pooled using libraries like Piscina for more efficiency.",
    "Streams are often used with HTTP — piping file uploads to S3 without buffering.",
    "Thread workers are initialized with a script file or inline code via DataURL.",
    "We use both: streams for ingestion and workers for transformation.",
    "Streams are memory-friendly; workers are CPU-friendly.",
    "Worker Threads use event-based messaging — it’s async but not event-loop safe.",
    "Avoid blocking the main thread with heavy loops — offload to worker threads.",
    "Transform streams let you manipulate data mid-flow — useful for filtering or reformatting.",
    "Don't use Worker Threads for everything — they have overhead and startup time.",
    "We stream log files to Elasticsearch using pipeline streams and gzip.",
    "Use `parentPort.postMessage()` and `worker.on('message')` to communicate with threads.",
    "Readable streams emit `data`, `end`, `error`, and `close` events — know them well.",
    "We use streaming to implement real-time file processing in our CLI tool.",
    "Workers can share memory with `SharedArrayBuffer` — but it’s advanced.",
    "Node core modules like `fs`, `http`, and `crypto` already support streams.",
    "For analytics, we stream data into ClickHouse in batches using transform streams.",
    "Worker Threads improve performance only if the task is truly parallelizable.",
    "We stream user uploads to virus scanners and CDN simultaneously.",
    "Use `pipeline()` to connect multiple streams with error handling.",
    "We use workers to run WASM code for performance-critical operations.",
    "Streams help avoid OOM errors when working with very large datasets.",
    "Thread termination must be handled cleanly — avoid zombie workers.",
    "You can stream data between workers too — via `MessageChannel`.",
    "Don’t mix up workers with child processes — they’re different abstractions.",
    "Choose the right tool: streams for flow control, workers for raw power.",
];
